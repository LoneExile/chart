global:
  environment: production

backend:
  image:
    repository: itzcrazykns1337/perplexica-backend
    tag: main
    pullPolicy: Always
  
  service:
    type: ClusterIP
    port: 3001

  env:
    SEARXNG_API_URL: http://searxng:8080

  persistence:
    dbstore:
      enabled: true
      storageClassName: ""
      size: 1Gi
    uploads:
      enabled: true
      storageClassName: ""
      size: 1Gi

frontend:
  image:
    repository: itzcrazykns1337/perplexica-frontend
    tag: main
    pullPolicy: Always
  
  service:
    type: ClusterIP
    port: 3000

  env:
    NEXT_PUBLIC_API_URL: http://127.0.0.1:3001/api
    NEXT_PUBLIC_WS_URL: ws://127.0.0.1:3001
config:
  config.toml: |
    [GENERAL]
    PORT = 3001 # Port to run the server on
    SIMILARITY_MEASURE = "cosine" # "cosine" or "dot"
    KEEP_ALIVE = "5m" # How long to keep Ollama models loaded into memory. (Instead of using -1 use "-1m")

    [API_KEYS]
    OPENAI = "" # OpenAI API key - sk-1234567890abcdef1234567890abcdef
    GROQ = "" # Groq API key - gsk_1234567890abcdef1234567890abcdef
    ANTHROPIC = "" # Anthropic API key - sk-ant-1234567890abcdef1234567890abcdef
    GEMINI = "" # Gemini API key - sk-1234567890abcdef1234567890abcdef

    [API_ENDPOINTS]
    SEARXNG = "http://localhost:32768" # SearxNG API URL
    OLLAMA = "" # Ollama API URL - http://host.docker.internal:11434

searxng:
  service:
    port: 8080

replicaCount: 1
